{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>NLP Sentiment Analysis for phrases/reviews \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from os import listdir\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import zipfile\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "####from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.svm import SVC\n",
    "####from textblob import TextBlob\n",
    "####from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import spacy\n",
    "import re,string,unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, GRU, Embedding,LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our Stopwords \n",
    "stopWords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stopWords) #NLTK stopwords have 127 words (Some words doesn't exist e.g: i'd, you'll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def loadVocab(filename):  \n",
    "    file = open(filename,'r')                             # open the file as read only \n",
    "    text = file.read()                                    # read all text\n",
    "    file.close()                                          # close the file\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def loadDocs(filename):            \n",
    "    file = open(filename, encoding=\"utf8\")                # open the file as read only\n",
    "    text = file.read()                                    # read all text\n",
    "    file.close()                                          # close the file\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn a doc into clean tokens\n",
    "def cleaningProcess(doc):\n",
    "    tokens = doc.split()                                  # split into tokens by white space  \n",
    "    table = str.maketrans('', '', punctuation)            # remove punctuation from each token\n",
    "    tokens = [w.translate(table) for w in tokens]         # Process of translating\n",
    "    tokens = [word for word in tokens if word.isalpha()]  # remove remaining tokens that are not alphabetic\n",
    "    tokens = [w for w in tokens if not w in stopWords]    # filter out stop words\n",
    "    tokens = [word for word in tokens if len(word) > 1]   # filter out short tokens\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list to file\n",
    "def saveList(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc, clean and return line of tokens ### deleted in other\n",
    "def docToLine(filename, vocab): \n",
    "    doc = loadDocs(filename)                             # load the doc \n",
    "    tokens = cleaningProcess(doc)                        # clean doc\n",
    "    tokens = [w for w in tokens if w in vocab]           # filter by vocab\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all docs in a directory\n",
    "def processDocs(directory, vocab):\n",
    "    lines = list()\n",
    "    for filename in listdir(directory):                  # walk through all files in the folder\n",
    "        if not filename.endswith(\".txt\"):                # skip files that do not have the right extension\n",
    "            continue\n",
    "        path = directory + '/' + filename                # create the full path of the file to open\n",
    "        line = docToLine(path, vocab)                    # load and clean the doc\n",
    "        lines.append(line)                               # add to list\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_filename = 'vocab.txt'\n",
    "vocab = loadVocab(vocab_filename)                        # load vocabulary\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "                                                         # prepare negative reviews\n",
    "negative_lines = processDocs('C:/Users/Jeyamaruthi/ML/neg', vocab)\n",
    "saveList(negative_lines, 'negative.txt')                 # Saving in a .txt file\n",
    "                                                         # prepare positive reviews\n",
    "positive_lines = processDocs('C:/Users/Jeyamaruthi/ML/pos', vocab)\n",
    "saveList(positive_lines, 'positive.txt')                 # Saving in a .txt file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'man unnatural pig opening scene terrific example absurd comedy formal orchestra audience turned insane violent mob crazy absurd time no general narrative eventually making just off putting era turned off cryptic dialogue make seem easy third grader technical level better might think good cinematography future great can seen briefly'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text = positive_lines + negative_lines\n",
    "y_train = [1.0] * len(positive_lines) + [0.0] * len(negative_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cartoon comedy ran time school life teaching profession lead believe satire much closer reality scramble survive financially insightful can see right pathetic pomp whole situation remind knew saw episode student repeatedly tried burn school immediately recalled classic line sack one expect many age think far fetched pity isnt'"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_filename = 'vocab.txt'\n",
    "vocab = loadVocab(vocab_filename)                        # load vocabulary\n",
    "vocab = vocab.split()\n",
    "vocab = set(vocab)\n",
    "                                                         # prepare negative reviews\n",
    "negative_lines_test = processDocs('C:/Users/Jeyamaruthi/ML/testing/neg', vocab)\n",
    "saveList(negative_lines, 'negative_test.txt')                 # Saving in a .txt file\n",
    "                                                         # prepare positive reviews\n",
    "positive_lines_test = processDocs('C:/Users/Jeyamaruthi/ML/testing/pos', vocab)\n",
    "saveList(positive_lines, 'positive_test.txt')                 # Saving in a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dragged movie far longer necessary terrific sea rescue just not care us closet character realized early forgotten much later time not care character really care cocky overconfident problem off kid better anyone else around no cluttered closet obstacle appears winning well past half way point stinker us told driven best no prior inkling foreshadowing magic keep turning off hour'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_lines_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_text = positive_lines_test + negative_lines_test  \n",
    "y_test = [1.0] * len(positive_lines_test) + [0.0] * len(negative_lines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went saw movie last night mine admit reluctant see knew able comedy wrong played character well played professionalism sign good movie can toy one exactly entire theater sold overcome laughter first half movie moved second half exiting theater not saw many many full grown men well trying desperately not let anyone see movie great suggest go see judge'"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us begin with the modeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer.fit_on_texts(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'movie': 1,\n",
       " 'film': 2,\n",
       " 'not': 3,\n",
       " 'one': 4,\n",
       " 'like': 5,\n",
       " 'just': 6,\n",
       " 'good': 7,\n",
       " 'time': 8,\n",
       " 'really': 9,\n",
       " 'see': 10,\n",
       " 'even': 11,\n",
       " 'can': 12,\n",
       " 'story': 13,\n",
       " 'no': 14,\n",
       " 'much': 15,\n",
       " 'get': 16,\n",
       " 'will': 17,\n",
       " 'bad': 18,\n",
       " 'great': 19,\n",
       " 'people': 20,\n",
       " 'well': 21,\n",
       " 'make': 22,\n",
       " 'also': 23,\n",
       " 'first': 24,\n",
       " 'made': 25,\n",
       " 'dont': 26,\n",
       " 'way': 27,\n",
       " 'think': 28,\n",
       " 'seen': 29,\n",
       " 'character': 30,\n",
       " 'watch': 31,\n",
       " 'many': 32,\n",
       " 'know': 33,\n",
       " 'never': 34,\n",
       " 'acting': 35,\n",
       " 'plot': 36,\n",
       " 'two': 37,\n",
       " 'love': 38,\n",
       " 'show': 39,\n",
       " 'best': 40,\n",
       " 'little': 41,\n",
       " 'ever': 42,\n",
       " 'life': 43,\n",
       " 'better': 44,\n",
       " 'off': 45,\n",
       " 'scene': 46,\n",
       " 'say': 47,\n",
       " 'end': 48,\n",
       " 'something': 49,\n",
       " 'still': 50,\n",
       " 'didnt': 51,\n",
       " 'go': 52,\n",
       " 'real': 53,\n",
       " 'thing': 54,\n",
       " 'back': 55,\n",
       " 'doesnt': 56,\n",
       " 'watching': 57,\n",
       " 'man': 58,\n",
       " 'funny': 59,\n",
       " 'find': 60,\n",
       " 'actually': 61,\n",
       " 'lot': 62,\n",
       " 'going': 63,\n",
       " 'work': 64,\n",
       " 'look': 65,\n",
       " 'cant': 66,\n",
       " 'though': 67,\n",
       " 'another': 68,\n",
       " 'part': 69,\n",
       " 'old': 70,\n",
       " 'want': 71,\n",
       " 'nothing': 72,\n",
       " 'every': 73,\n",
       " 'cast': 74,\n",
       " 'around': 75,\n",
       " 'quite': 76,\n",
       " 'pretty': 77,\n",
       " 'seems': 78,\n",
       " 'thought': 79,\n",
       " 'fact': 80,\n",
       " 'enough': 81,\n",
       " 'got': 82,\n",
       " 'director': 83,\n",
       " 'take': 84,\n",
       " 'give': 85,\n",
       " 'now': 86,\n",
       " 'music': 87,\n",
       " 'horror': 88,\n",
       " 'us': 89,\n",
       " 'isnt': 90,\n",
       " 'saw': 91,\n",
       " 'young': 92,\n",
       " 'whole': 93,\n",
       " 'may': 94,\n",
       " 'always': 95,\n",
       " 'must': 96,\n",
       " 'role': 97,\n",
       " 'least': 98,\n",
       " 'long': 99,\n",
       " 'almost': 100,\n",
       " 'comedy': 101,\n",
       " 'without': 102,\n",
       " 'interesting': 103,\n",
       " 'done': 104,\n",
       " 'right': 105,\n",
       " 'come': 106,\n",
       " 'bit': 107,\n",
       " 'series': 108,\n",
       " 'big': 109,\n",
       " 'original': 110,\n",
       " 'world': 111,\n",
       " 'guy': 112,\n",
       " 'might': 113,\n",
       " 'action': 114,\n",
       " 'far': 115,\n",
       " 'feel': 116,\n",
       " 'point': 117,\n",
       " 'script': 118,\n",
       " 'thats': 119,\n",
       " 'new': 120,\n",
       " 'anything': 121,\n",
       " 'kind': 122,\n",
       " 'probably': 123,\n",
       " 'performance': 124,\n",
       " 'found': 125,\n",
       " 'fun': 126,\n",
       " 'played': 127,\n",
       " 'away': 128,\n",
       " 'since': 129,\n",
       " 'last': 130,\n",
       " 'rather': 131,\n",
       " 'worst': 132,\n",
       " 'anyone': 133,\n",
       " 'believe': 134,\n",
       " 'trying': 135,\n",
       " 'family': 136,\n",
       " 'course': 137,\n",
       " 'making': 138,\n",
       " 'main': 139,\n",
       " 'put': 140,\n",
       " 'worth': 141,\n",
       " 'looking': 142,\n",
       " 'ending': 143,\n",
       " 'yet': 144,\n",
       " 'different': 145,\n",
       " 'woman': 146,\n",
       " 'watched': 147,\n",
       " 'girl': 148,\n",
       " 'hard': 149,\n",
       " 'screen': 150,\n",
       " 'especially': 151,\n",
       " 'place': 152,\n",
       " 'sure': 153,\n",
       " 'wasnt': 154,\n",
       " 'reason': 155,\n",
       " 'sense': 156,\n",
       " 'book': 157,\n",
       " 'play': 158,\n",
       " 'job': 159,\n",
       " 'together': 160,\n",
       " 'said': 161,\n",
       " 'seem': 162,\n",
       " 'set': 163,\n",
       " 'money': 164,\n",
       " 'everything': 165,\n",
       " 'audience': 166,\n",
       " 'someone': 167,\n",
       " 'three': 168,\n",
       " 'actor': 169,\n",
       " 'left': 170,\n",
       " 'idea': 171,\n",
       " 'true': 172,\n",
       " 'fan': 173,\n",
       " 'used': 174,\n",
       " 'special': 175,\n",
       " 'seeing': 176,\n",
       " 'day': 177,\n",
       " 'version': 178,\n",
       " 'completely': 179,\n",
       " 'beautiful': 180,\n",
       " 'shot': 181,\n",
       " 'excellent': 182,\n",
       " 'else': 183,\n",
       " 'later': 184,\n",
       " 'short': 185,\n",
       " 'everyone': 186,\n",
       " 'simply': 187,\n",
       " 'youre': 188,\n",
       " 'along': 189,\n",
       " 'poor': 190,\n",
       " 'help': 191,\n",
       " 'use': 192,\n",
       " 'read': 193,\n",
       " 'recommend': 194,\n",
       " 'wife': 195,\n",
       " 'half': 196,\n",
       " 'nice': 197,\n",
       " 'mind': 198,\n",
       " 'need': 199,\n",
       " 'couple': 200,\n",
       " 'high': 201,\n",
       " 'boring': 202,\n",
       " 'start': 203,\n",
       " 'enjoy': 204,\n",
       " 'stupid': 205,\n",
       " 'production': 206,\n",
       " 'try': 207,\n",
       " 'understand': 208,\n",
       " 'getting': 209,\n",
       " 'home': 210,\n",
       " 'came': 211,\n",
       " 'rest': 212,\n",
       " 'truly': 213,\n",
       " 'either': 214,\n",
       " 'year': 215,\n",
       " 'given': 216,\n",
       " 'wrong': 217,\n",
       " 'tell': 218,\n",
       " 'budget': 219,\n",
       " 'camera': 220,\n",
       " 'line': 221,\n",
       " 'classic': 222,\n",
       " 'death': 223,\n",
       " 'school': 224,\n",
       " 'men': 225,\n",
       " 'next': 226,\n",
       " 'keep': 227,\n",
       " 'mean': 228,\n",
       " 'went': 229,\n",
       " 'name': 230,\n",
       " 'second': 231,\n",
       " 'terrible': 232,\n",
       " 'war': 233,\n",
       " 'person': 234,\n",
       " 'couldnt': 235,\n",
       " 'however': 236,\n",
       " 'instead': 237,\n",
       " 'maybe': 238,\n",
       " 'playing': 239,\n",
       " 'others': 240,\n",
       " 'full': 241,\n",
       " 'sex': 242,\n",
       " 'awful': 243,\n",
       " 'night': 244,\n",
       " 'remember': 245,\n",
       " 'although': 246,\n",
       " 'human': 247,\n",
       " 'laugh': 248,\n",
       " 'often': 249,\n",
       " 'wonderful': 250,\n",
       " 'dialogue': 251,\n",
       " 'piece': 252,\n",
       " 'video': 253,\n",
       " 'early': 254,\n",
       " 'small': 255,\n",
       " 'perfect': 256,\n",
       " 'face': 257,\n",
       " 'let': 258,\n",
       " 'liked': 259,\n",
       " 'episode': 260,\n",
       " 'sort': 261,\n",
       " 'entertaining': 262,\n",
       " 'absolutely': 263,\n",
       " 'black': 264,\n",
       " 'become': 265,\n",
       " 'father': 266,\n",
       " 'friend': 267,\n",
       " 'certainly': 268,\n",
       " 'entire': 269,\n",
       " 'style': 270,\n",
       " 'case': 271,\n",
       " 'loved': 272,\n",
       " 'top': 273,\n",
       " 'totally': 274,\n",
       " 'mother': 275,\n",
       " 'title': 276,\n",
       " 'definitely': 277,\n",
       " 'humor': 278,\n",
       " 'sound': 279,\n",
       " 'worse': 280,\n",
       " 'several': 281,\n",
       " 'able': 282,\n",
       " 'seemed': 283,\n",
       " 'written': 284,\n",
       " 'head': 285,\n",
       " 'felt': 286,\n",
       " 'wanted': 287,\n",
       " 'supposed': 288,\n",
       " 'lead': 289,\n",
       " 'wont': 290,\n",
       " 'called': 291,\n",
       " 'hope': 292,\n",
       " 'beginning': 293,\n",
       " 'care': 294,\n",
       " 'problem': 295,\n",
       " 'waste': 296,\n",
       " 'guess': 297,\n",
       " 'game': 298,\n",
       " 'live': 299,\n",
       " 'becomes': 300,\n",
       " 'already': 301,\n",
       " 'low': 302,\n",
       " 'example': 303,\n",
       " 'based': 304,\n",
       " 'drama': 305,\n",
       " 'turn': 306,\n",
       " 'house': 307,\n",
       " 'picture': 308,\n",
       " 'quality': 309,\n",
       " 'cinema': 310,\n",
       " 'matter': 311,\n",
       " 'direction': 312,\n",
       " 'group': 313,\n",
       " 'final': 314,\n",
       " 'horrible': 315,\n",
       " 'gave': 316,\n",
       " 'dead': 317,\n",
       " 'star': 318,\n",
       " 'flick': 319,\n",
       " 'throughout': 320,\n",
       " 'lost': 321,\n",
       " 'stuff': 322,\n",
       " 'enjoyed': 323,\n",
       " 'writing': 324,\n",
       " 'killed': 325,\n",
       " 'expect': 326,\n",
       " 'fine': 327,\n",
       " 'boy': 328,\n",
       " 'youll': 329,\n",
       " 'act': 330,\n",
       " 'took': 331,\n",
       " 'finally': 332,\n",
       " 'side': 333,\n",
       " 'history': 334,\n",
       " 'favorite': 335,\n",
       " 'happens': 336,\n",
       " 'brilliant': 337,\n",
       " 'car': 338,\n",
       " 'amazing': 339,\n",
       " 'past': 340,\n",
       " 'heard': 341,\n",
       " 'run': 342,\n",
       " 'kill': 343,\n",
       " 'experience': 344,\n",
       " 'decent': 345,\n",
       " 'perhaps': 346,\n",
       " 'viewer': 347,\n",
       " 'thinking': 348,\n",
       " 'son': 349,\n",
       " 'behind': 350,\n",
       " 'looked': 351,\n",
       " 'etc': 352,\n",
       " 'late': 353,\n",
       " 'town': 354,\n",
       " 'genre': 355,\n",
       " 'dark': 356,\n",
       " 'type': 357,\n",
       " 'told': 358,\n",
       " 'theyre': 359,\n",
       " 'directed': 360,\n",
       " 'lack': 361,\n",
       " 'hilarious': 362,\n",
       " 'serious': 363,\n",
       " 'extremely': 364,\n",
       " 'score': 365,\n",
       " 'shown': 366,\n",
       " 'feeling': 367,\n",
       " 'taken': 368,\n",
       " 'daughter': 369,\n",
       " 'coming': 370,\n",
       " 'wouldnt': 371,\n",
       " 'wonder': 372,\n",
       " 'involved': 373,\n",
       " 'moment': 374,\n",
       " 'across': 375,\n",
       " 'known': 376,\n",
       " 'leave': 377,\n",
       " 'chance': 378,\n",
       " 'hour': 379,\n",
       " 'including': 380,\n",
       " 'happen': 381,\n",
       " 'fight': 382,\n",
       " 'obviously': 383,\n",
       " 'cannot': 384,\n",
       " 'cool': 385,\n",
       " 'attempt': 386,\n",
       " 'actress': 387,\n",
       " 'shes': 388,\n",
       " 'opening': 389,\n",
       " 'complete': 390,\n",
       " 'simple': 391,\n",
       " 'kid': 392,\n",
       " 'saying': 393,\n",
       " 'particularly': 394,\n",
       " 'talent': 395,\n",
       " 'strong': 396,\n",
       " 'killer': 397,\n",
       " 'except': 398,\n",
       " 'stop': 399,\n",
       " 'obvious': 400,\n",
       " 'released': 401,\n",
       " 'evil': 402,\n",
       " 'soon': 403,\n",
       " 'heart': 404,\n",
       " 'violence': 405,\n",
       " 'art': 406,\n",
       " 'happened': 407,\n",
       " 'save': 408,\n",
       " 'exactly': 409,\n",
       " 'ago': 410,\n",
       " 'close': 411,\n",
       " 'child': 412,\n",
       " 'reality': 413,\n",
       " 'relationship': 414,\n",
       " 'voice': 415,\n",
       " 'white': 416,\n",
       " 'order': 417,\n",
       " 'highly': 418,\n",
       " 'hand': 419,\n",
       " 'song': 420,\n",
       " 'slow': 421,\n",
       " 'hit': 422,\n",
       " 'crap': 423,\n",
       " 'important': 424,\n",
       " 'whose': 425,\n",
       " 'turned': 426,\n",
       " 'interest': 427,\n",
       " 'knew': 428,\n",
       " 'documentary': 429,\n",
       " 'cinematography': 430,\n",
       " 'sometimes': 431,\n",
       " 'huge': 432,\n",
       " 'started': 433,\n",
       " 'view': 434,\n",
       " 'wish': 435,\n",
       " 'silly': 436,\n",
       " 'career': 437,\n",
       " 'taking': 438,\n",
       " 'despite': 439,\n",
       " 'annoying': 440,\n",
       " 'living': 441,\n",
       " 'cut': 442,\n",
       " 'female': 443,\n",
       " 'possible': 444,\n",
       " 'sad': 445,\n",
       " 'word': 446,\n",
       " 'ridiculous': 447,\n",
       " 'running': 448,\n",
       " 'usually': 449,\n",
       " 'police': 450,\n",
       " 'murder': 451,\n",
       " 'dialog': 452,\n",
       " 'number': 453,\n",
       " 'change': 454,\n",
       " 'opinion': 455,\n",
       " 'attention': 456,\n",
       " 'call': 457,\n",
       " 'usual': 458,\n",
       " 'somewhat': 459,\n",
       " 'cheap': 460,\n",
       " 'local': 461,\n",
       " 'mostly': 462,\n",
       " 'today': 463,\n",
       " 'husband': 464,\n",
       " 'disappointed': 465,\n",
       " 'hero': 466,\n",
       " 'soundtrack': 467,\n",
       " 'upon': 468,\n",
       " 'country': 469,\n",
       " 'hell': 470,\n",
       " 'novel': 471,\n",
       " 'beyond': 472,\n",
       " 'sequence': 473,\n",
       " 'body': 474,\n",
       " 'arent': 475,\n",
       " 'level': 476,\n",
       " 'due': 477,\n",
       " 'single': 478,\n",
       " 'major': 479,\n",
       " 'gore': 480,\n",
       " 'alone': 481,\n",
       " 'power': 482,\n",
       " 'tried': 483,\n",
       " 'talking': 484,\n",
       " 'appears': 485,\n",
       " 'certain': 486,\n",
       " 'blood': 487,\n",
       " 'room': 488,\n",
       " 'mention': 489,\n",
       " 'brother': 490,\n",
       " 'television': 491,\n",
       " 'havent': 492,\n",
       " 'review': 493,\n",
       " 'showing': 494,\n",
       " 'clear': 495,\n",
       " 'hate': 496,\n",
       " 'age': 497,\n",
       " 'seriously': 498,\n",
       " 'giving': 499,\n",
       " 'subject': 500,\n",
       " 'predictable': 501,\n",
       " 'surprised': 502,\n",
       " 'enjoyable': 503,\n",
       " 'filmed': 504,\n",
       " 'deal': 505,\n",
       " 'happy': 506,\n",
       " 'team': 507,\n",
       " 'strange': 508,\n",
       " 'suspense': 509,\n",
       " 'clearly': 510,\n",
       " 'kept': 511,\n",
       " 'similar': 512,\n",
       " 'bunch': 513,\n",
       " 'modern': 514,\n",
       " 'storyline': 515,\n",
       " 'message': 516,\n",
       " 'release': 517,\n",
       " 'named': 518,\n",
       " 'light': 519,\n",
       " 'moving': 520,\n",
       " 'sequel': 521,\n",
       " 'doubt': 522,\n",
       " 'bring': 523,\n",
       " 'musical': 524,\n",
       " 'romantic': 525,\n",
       " 'monster': 526,\n",
       " 'theme': 527,\n",
       " 'fall': 528,\n",
       " 'near': 529,\n",
       " 'scary': 530,\n",
       " 'talk': 531,\n",
       " 'add': 532,\n",
       " 'effort': 533,\n",
       " 'four': 534,\n",
       " 'dull': 535,\n",
       " 'none': 536,\n",
       " 'easily': 537,\n",
       " 'crew': 538,\n",
       " 'realistic': 539,\n",
       " 'among': 540,\n",
       " 'ten': 541,\n",
       " 'working': 542,\n",
       " 'typical': 543,\n",
       " 'brought': 544,\n",
       " 'buy': 545,\n",
       " 'basically': 546,\n",
       " 'whether': 547,\n",
       " 'easy': 548,\n",
       " 'within': 549,\n",
       " 'greatest': 550,\n",
       " 'writer': 551,\n",
       " 'comic': 552,\n",
       " 'viewing': 553,\n",
       " 'move': 554,\n",
       " 'overall': 555,\n",
       " 'believable': 556,\n",
       " 'middle': 557,\n",
       " 'dog': 558,\n",
       " 'future': 559,\n",
       " 'using': 560,\n",
       " 'entertainment': 561,\n",
       " 'feature': 562,\n",
       " 'editing': 563,\n",
       " 'rating': 564,\n",
       " 'actual': 565,\n",
       " 'material': 566,\n",
       " 'thriller': 567,\n",
       " 'form': 568,\n",
       " 'straight': 569,\n",
       " 'hear': 570,\n",
       " 'apparently': 571,\n",
       " 'situation': 572,\n",
       " 'premise': 573,\n",
       " 'sit': 574,\n",
       " 'expected': 575,\n",
       " 'surprise': 576,\n",
       " 'famous': 577,\n",
       " 'emotional': 578,\n",
       " 'supporting': 579,\n",
       " 'killing': 580,\n",
       " 'learn': 581,\n",
       " 'nearly': 582,\n",
       " 'decided': 583,\n",
       " 'footage': 584,\n",
       " 'class': 585,\n",
       " 'youve': 586,\n",
       " 'difficult': 587,\n",
       " 'forced': 588,\n",
       " 'city': 589,\n",
       " 'period': 590,\n",
       " 'particular': 591,\n",
       " 'stay': 592,\n",
       " 'gone': 593,\n",
       " 'figure': 594,\n",
       " 'theater': 595,\n",
       " 'sister': 596,\n",
       " 'die': 597,\n",
       " 'previous': 598,\n",
       " 'needed': 599,\n",
       " 'rent': 600,\n",
       " 'atmosphere': 601,\n",
       " 'weak': 602,\n",
       " 'tale': 603,\n",
       " 'gay': 604,\n",
       " 'spent': 605,\n",
       " 'cheesy': 606,\n",
       " 'personal': 607,\n",
       " 'became': 608,\n",
       " 'copy': 609,\n",
       " 'open': 610,\n",
       " 'memorable': 611,\n",
       " 'average': 612,\n",
       " 'begin': 613,\n",
       " 'interested': 614,\n",
       " 'write': 615,\n",
       " 'minute': 616,\n",
       " 'crime': 617,\n",
       " 'five': 618,\n",
       " 'masterpiece': 619,\n",
       " 'fantastic': 620,\n",
       " 'forget': 621,\n",
       " 'follow': 622,\n",
       " 'poorly': 623,\n",
       " 'perfectly': 624,\n",
       " 'truth': 625,\n",
       " 'space': 626,\n",
       " 'result': 627,\n",
       " 'inside': 628,\n",
       " 'whats': 629,\n",
       " 'somehow': 630,\n",
       " 'quickly': 631,\n",
       " 'imagine': 632,\n",
       " 'sorry': 633,\n",
       " 'question': 634,\n",
       " 'background': 635,\n",
       " 'various': 636,\n",
       " 'box': 637,\n",
       " 'incredibly': 638,\n",
       " 'deep': 639,\n",
       " 'comment': 640,\n",
       " 'male': 641,\n",
       " 'acted': 642,\n",
       " 'unique': 643,\n",
       " 'yes': 644,\n",
       " 'society': 645,\n",
       " 'worked': 646,\n",
       " 'fairly': 647,\n",
       " 'effect': 648,\n",
       " 'reading': 649,\n",
       " 'setting': 650,\n",
       " 'wait': 651,\n",
       " 'towards': 652,\n",
       " 'total': 653,\n",
       " 'possibly': 654,\n",
       " 'sexual': 655,\n",
       " 'meet': 656,\n",
       " 'powerful': 657,\n",
       " 'wasted': 658,\n",
       " 'appear': 659,\n",
       " 'romance': 660,\n",
       " 'check': 661,\n",
       " 'superb': 662,\n",
       " 'portrayed': 663,\n",
       " 'stand': 664,\n",
       " 'lame': 665,\n",
       " 'realize': 666,\n",
       " 'shame': 667,\n",
       " 'front': 668,\n",
       " 'please': 669,\n",
       " 'brings': 670,\n",
       " 'admit': 671,\n",
       " 'clever': 672,\n",
       " 'cover': 673,\n",
       " 'badly': 674,\n",
       " 'beauty': 675,\n",
       " 'caught': 676,\n",
       " 'general': 677,\n",
       " 'business': 678,\n",
       " 'eventually': 679,\n",
       " 'forward': 680,\n",
       " 'laughing': 681,\n",
       " 'deserves': 682,\n",
       " 'fast': 683,\n",
       " 'older': 684,\n",
       " 'anyway': 685,\n",
       " 'manages': 686,\n",
       " 'weird': 687,\n",
       " 'animation': 688,\n",
       " 'ended': 689,\n",
       " 'eye': 690,\n",
       " 'agree': 691,\n",
       " 'earlier': 692,\n",
       " 'pay': 693,\n",
       " 'mess': 694,\n",
       " 'joke': 695,\n",
       " 'fails': 696,\n",
       " 'success': 697,\n",
       " 'girlfriend': 698,\n",
       " 'large': 699,\n",
       " 'leading': 700,\n",
       " 'political': 701,\n",
       " 'mystery': 702,\n",
       " 'free': 703,\n",
       " 'nature': 704,\n",
       " 'plenty': 705,\n",
       " 'expecting': 706,\n",
       " 'following': 707,\n",
       " 'hot': 708,\n",
       " 'remake': 709,\n",
       " 'rich': 710,\n",
       " 'screenplay': 711,\n",
       " 'dance': 712,\n",
       " 'dumb': 713,\n",
       " 'ask': 714,\n",
       " 'directing': 715,\n",
       " 'outside': 716,\n",
       " 'created': 717,\n",
       " 'battle': 718,\n",
       " 'miss': 719,\n",
       " 'cop': 720,\n",
       " 'creepy': 721,\n",
       " 'meant': 722,\n",
       " 'escape': 723,\n",
       " 'note': 724,\n",
       " 'visual': 725,\n",
       " 'missing': 726,\n",
       " 'fighting': 727,\n",
       " 'create': 728,\n",
       " 'indeed': 729,\n",
       " 'development': 730,\n",
       " 'present': 731,\n",
       " 'unless': 732,\n",
       " 'stage': 733,\n",
       " 'speak': 734,\n",
       " 'talented': 735,\n",
       " 'dramatic': 736,\n",
       " 'follows': 737,\n",
       " 'pace': 738,\n",
       " 'recently': 739,\n",
       " 'telling': 740,\n",
       " 'whatever': 741,\n",
       " 'twist': 742,\n",
       " 'hold': 743,\n",
       " 'amount': 744,\n",
       " 'fit': 745,\n",
       " 'slightly': 746,\n",
       " 'familiar': 747,\n",
       " 'cause': 748,\n",
       " 'water': 749,\n",
       " 'cute': 750,\n",
       " 'appreciate': 751,\n",
       " 'waiting': 752,\n",
       " 'third': 753,\n",
       " 'died': 754,\n",
       " 'odd': 755,\n",
       " 'doctor': 756,\n",
       " 'drug': 757,\n",
       " 'portrayal': 758,\n",
       " 'younger': 759,\n",
       " 'air': 760,\n",
       " 'plain': 761,\n",
       " 'missed': 762,\n",
       " 'produced': 763,\n",
       " 'entirely': 764,\n",
       " 'store': 765,\n",
       " 'pure': 766,\n",
       " 'decides': 767,\n",
       " 'hardly': 768,\n",
       " 'cartoon': 769,\n",
       " 'former': 770,\n",
       " 'villain': 771,\n",
       " 'crazy': 772,\n",
       " 'longer': 773,\n",
       " 'value': 774,\n",
       " 'common': 775,\n",
       " 'train': 776,\n",
       " 'mentioned': 777,\n",
       " 'credit': 778,\n",
       " 'break': 779,\n",
       " 'convincing': 780,\n",
       " 'decide': 781,\n",
       " 'bother': 782,\n",
       " 'era': 783,\n",
       " 'public': 784,\n",
       " 'humour': 785,\n",
       " 'bored': 786,\n",
       " 'party': 787,\n",
       " 'biggest': 788,\n",
       " 'popular': 789,\n",
       " 'wrote': 790,\n",
       " 'company': 791,\n",
       " 'rate': 792,\n",
       " 'involving': 793,\n",
       " 'list': 794,\n",
       " 'college': 795,\n",
       " 'potential': 796,\n",
       " 'unfortunately': 797,\n",
       " 'language': 798,\n",
       " 'choice': 799,\n",
       " 'nudity': 800,\n",
       " 'tension': 801,\n",
       " 'incredible': 802,\n",
       " 'intelligent': 803,\n",
       " 'pathetic': 804,\n",
       " 'fake': 805,\n",
       " 'scifi': 806,\n",
       " 'season': 807,\n",
       " 'depth': 808,\n",
       " 'meaning': 809,\n",
       " 'concept': 810,\n",
       " 'filled': 811,\n",
       " 'violent': 812,\n",
       " 'sick': 813,\n",
       " 'married': 814,\n",
       " 'bizarre': 815,\n",
       " 'hair': 816,\n",
       " 'match': 817,\n",
       " 'successful': 818,\n",
       " 'lady': 819,\n",
       " 'werent': 820,\n",
       " 'avoid': 821,\n",
       " 'bought': 822,\n",
       " 'honest': 823,\n",
       " 'spend': 824,\n",
       " 'pointless': 825,\n",
       " 'otherwise': 826,\n",
       " 'recent': 827,\n",
       " 'gang': 828,\n",
       " 'garbage': 829,\n",
       " 'pick': 830,\n",
       " 'control': 831,\n",
       " 'exciting': 832,\n",
       " 'amusing': 833,\n",
       " 'flat': 834,\n",
       " 'island': 835,\n",
       " 'changed': 836,\n",
       " 'available': 837,\n",
       " 'trouble': 838,\n",
       " 'barely': 839,\n",
       " 'focus': 840,\n",
       " 'considering': 841,\n",
       " 'fire': 842,\n",
       " 'gun': 843,\n",
       " 'casting': 844,\n",
       " 'showed': 845,\n",
       " 'ability': 846,\n",
       " 'positive': 847,\n",
       " 'likely': 848,\n",
       " 'dream': 849,\n",
       " 'respect': 850,\n",
       " 'sitting': 851,\n",
       " 'solid': 852,\n",
       " 'explain': 853,\n",
       " 'culture': 854,\n",
       " 'accent': 855,\n",
       " 'return': 856,\n",
       " 'mood': 857,\n",
       " 'compared': 858,\n",
       " 'effective': 859,\n",
       " 'failed': 860,\n",
       " 'normal': 861,\n",
       " 'immediately': 862,\n",
       " 'leaving': 863,\n",
       " 'cinematic': 864,\n",
       " 'apart': 865,\n",
       " 'street': 866,\n",
       " 'added': 867,\n",
       " 'impressive': 868,\n",
       " 'suddenly': 869,\n",
       " 'basic': 870,\n",
       " 'glad': 871,\n",
       " 'literally': 872,\n",
       " 'okay': 873,\n",
       " 'alive': 874,\n",
       " 'considered': 875,\n",
       " 'impossible': 876,\n",
       " 'chemistry': 877,\n",
       " 'purpose': 878,\n",
       " 'rock': 879,\n",
       " 'social': 880,\n",
       " 'suppose': 881,\n",
       " 'brain': 882,\n",
       " 'awesome': 883,\n",
       " 'singing': 884,\n",
       " 'genius': 885,\n",
       " 'bed': 886,\n",
       " 'shooting': 887,\n",
       " 'presence': 888,\n",
       " 'consider': 889,\n",
       " 'scenery': 890,\n",
       " 'shoot': 891,\n",
       " 'century': 892,\n",
       " 'state': 893,\n",
       " 'journey': 894,\n",
       " 'sexy': 895,\n",
       " 'secret': 896,\n",
       " 'thrown': 897,\n",
       " 'historical': 898,\n",
       " 'fair': 899,\n",
       " 'subtle': 900,\n",
       " 'photography': 901,\n",
       " 'disturbing': 902,\n",
       " 'week': 903,\n",
       " 'complex': 904,\n",
       " 'neither': 905,\n",
       " 'dancing': 906,\n",
       " 'touch': 907,\n",
       " 'western': 908,\n",
       " 'ship': 909,\n",
       " 'taste': 910,\n",
       " 'remains': 911,\n",
       " 'trash': 912,\n",
       " 'managed': 913,\n",
       " 'studio': 914,\n",
       " 'constantly': 915,\n",
       " 'intended': 916,\n",
       " 'nowhere': 917,\n",
       " 'innocent': 918,\n",
       " 'track': 919,\n",
       " 'boyfriend': 920,\n",
       " 'office': 921,\n",
       " 'plus': 922,\n",
       " 'standard': 923,\n",
       " 'win': 924,\n",
       " 'spirit': 925,\n",
       " 'beautifully': 926,\n",
       " 'somewhere': 927,\n",
       " 'sweet': 928,\n",
       " 'starring': 929,\n",
       " 'fantasy': 930,\n",
       " 'project': 931,\n",
       " 'tough': 932,\n",
       " 'band': 933,\n",
       " 'walk': 934,\n",
       " 'appearance': 935,\n",
       " 'aspect': 936,\n",
       " 'recommended': 937,\n",
       " 'fear': 938,\n",
       " 'lovely': 939,\n",
       " 'surprisingly': 940,\n",
       " 'impression': 941,\n",
       " 'building': 942,\n",
       " 'makeup': 943,\n",
       " 'ultimately': 944,\n",
       " 'prison': 945,\n",
       " 'smart': 946,\n",
       " 'teen': 947,\n",
       " 'trip': 948,\n",
       " 'narrative': 949,\n",
       " 'adult': 950,\n",
       " 'terrific': 951,\n",
       " 'earth': 952,\n",
       " 'laughed': 953,\n",
       " 'location': 954,\n",
       " 'self': 955,\n",
       " 'conclusion': 956,\n",
       " 'filming': 957,\n",
       " 'hoping': 958,\n",
       " 'presented': 959,\n",
       " 'tired': 960,\n",
       " 'stick': 961,\n",
       " 'tone': 962,\n",
       " 'slowly': 963,\n",
       " 'brief': 964,\n",
       " 'silent': 965,\n",
       " 'painful': 966,\n",
       " 'sent': 967,\n",
       " 'fell': 968,\n",
       " 'cult': 969,\n",
       " 'appeal': 970,\n",
       " 'disappointing': 971,\n",
       " 'pull': 972,\n",
       " 'utterly': 973,\n",
       " 'government': 974,\n",
       " 'lived': 975,\n",
       " 'pass': 976,\n",
       " 'door': 977,\n",
       " 'military': 978,\n",
       " 'race': 979,\n",
       " 'road': 980,\n",
       " 'force': 981,\n",
       " 'cold': 982,\n",
       " 'science': 983,\n",
       " 'mysterious': 984,\n",
       " 'laughable': 985,\n",
       " 'notice': 986,\n",
       " 'confusing': 987,\n",
       " 'oh': 988,\n",
       " 'rare': 989,\n",
       " 'giant': 990,\n",
       " 'generally': 991,\n",
       " 'offer': 992,\n",
       " 'adaptation': 993,\n",
       " 'student': 994,\n",
       " 'emotion': 995,\n",
       " 'baby': 996,\n",
       " 'seemingly': 997,\n",
       " 'catch': 998,\n",
       " 'contains': 999,\n",
       " 'adventure': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tokens = tokenizer.texts_to_sequences(x_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[769,\n",
       " 101,\n",
       " 1442,\n",
       " 8,\n",
       " 224,\n",
       " 43,\n",
       " 2495,\n",
       " 3906,\n",
       " 289,\n",
       " 134,\n",
       " 1567,\n",
       " 15,\n",
       " 1958,\n",
       " 413,\n",
       " 1341,\n",
       " 6484,\n",
       " 3497,\n",
       " 12,\n",
       " 10,\n",
       " 105,\n",
       " 804,\n",
       " 93,\n",
       " 572,\n",
       " 2319,\n",
       " 428,\n",
       " 91,\n",
       " 260,\n",
       " 994,\n",
       " 2137,\n",
       " 483,\n",
       " 2579,\n",
       " 224,\n",
       " 862,\n",
       " 7537,\n",
       " 222,\n",
       " 221,\n",
       " 6301,\n",
       " 4,\n",
       " 326,\n",
       " 32,\n",
       " 497,\n",
       " 28,\n",
       " 115,\n",
       " 4583,\n",
       " 1779,\n",
       " 90]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tokens[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocesseing for Sequential Deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2447, 1271,   34, 1118,  191,  866,  875,  247,  165,   63,  224,\n",
       "         64, 1316,  311,   20,   28, 4293,    6,  321,  748, 5892, 1854,\n",
       "        233, 2131, 1791, 5892, 2725,  226,   48,  216, 1861,  299, 2552,\n",
       "        102,  210,  561, 2661, 1321, 1020,  165, 2225,   10,    5, 4293,\n",
       "       3166,  710,   58,  165,  111, 4687,   22, 1861, 2227,   10,   12,\n",
       "        299, 2534,  102, 1908,   12,  559,  931,  138,  897,  866, 3164,\n",
       "       9007,   73,  554,   66, 1427,   45, 7313,  216, 6232,  284, 5571,\n",
       "        380,  146,  230,   82, 3241, 1626,  210,  301,  174,   90,    3,\n",
       "        174, 3521, 5669,    5,  710,  382, 1906,  343,   38, 1452,  154,\n",
       "       1257,   36,  125,    4, 8550, 1831,  101, 3088,  333,  858, 1450,\n",
       "         64,  311,   39,    5,   49, 3332, 1626,  226,  177,  419,  138,\n",
       "        205, 1861,    5,  710,   20,   26,   33,  164,   85, 4293,  237,\n",
       "        560,    5,  238,    2,   17, 3431,  191,  240])"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2447, 1271,   34, 1118,  191,  866,  875,  247,  165,   63,  224,\n",
       "         64, 1316,  311,   20,   28, 4293,    6,  321,  748, 5892, 1854,\n",
       "        233, 2131, 1791, 5892, 2725,  226,   48,  216, 1861,  299, 2552,\n",
       "        102,  210,  561, 2661, 1321, 1020,  165, 2225,   10,    5, 4293,\n",
       "       3166,  710,   58,  165,  111, 4687,   22, 1861, 2227,   10,   12,\n",
       "        299, 2534,  102, 1908,   12,  559,  931,  138,  897,  866, 3164,\n",
       "       9007,   73,  554,   66, 1427,   45, 7313,  216, 6232,  284, 5571,\n",
       "        380,  146,  230,   82, 3241, 1626,  210,  301,  174,   90,    3,\n",
       "        174, 3521, 5669,    5,  710,  382, 1906,  343,   38, 1452,  154,\n",
       "       1257,   36,  125,    4, 8550, 1831,  101, 3088,  333,  858, 1450,\n",
       "         64,  311,   39,    5,   49, 3332, 1626,  226,  177,  419,  138,\n",
       "        205, 1861,    5,  710,   20,   26,   33,  164,   85, 4293,  237,\n",
       "        560,    5,  238,    2,   17, 3431,  191,  240])"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tokens = tokenizer.texts_to_sequences(x_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 46, 140,  54, ..., 100,  40, 132])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.94654"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94538"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(num_tokens < max_tokens) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = 'pre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_pad = pad_sequences(x_train_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_pad = pad_sequences(x_test_tokens, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 206)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 206)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2447, 1271,   34, 1118,  191,  866,  875,  247,  165,   63,  224,\n",
       "         64, 1316,  311,   20,   28, 4293,    6,  321,  748, 5892, 1854,\n",
       "        233, 2131, 1791, 5892, 2725,  226,   48,  216, 1861,  299, 2552,\n",
       "        102,  210,  561, 2661, 1321, 1020,  165, 2225,   10,    5, 4293,\n",
       "       3166,  710,   58,  165,  111, 4687,   22, 1861, 2227,   10,   12,\n",
       "        299, 2534,  102, 1908,   12,  559,  931,  138,  897,  866, 3164,\n",
       "       9007,   73,  554,   66, 1427,   45, 7313,  216, 6232,  284, 5571,\n",
       "        380,  146,  230,   82, 3241, 1626,  210,  301,  174,   90,    3,\n",
       "        174, 3521, 5669,    5,  710,  382, 1906,  343,   38, 1452,  154,\n",
       "       1257,   36,  125,    4, 8550, 1831,  101, 3088,  333,  858, 1450,\n",
       "         64,  311,   39,    5,   49, 3332, 1626,  226,  177,  419,  138,\n",
       "        205, 1861,    5,  710,   20,   26,   33,  164,   85, 4293,  237,\n",
       "        560,    5,  238,    2,   17, 3431,  191,  240])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(x_train_tokens[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "       2447, 1271,   34, 1118,  191,  866,  875,  247,  165,   63,  224,\n",
       "         64, 1316,  311,   20,   28, 4293,    6,  321,  748, 5892, 1854,\n",
       "        233, 2131, 1791, 5892, 2725,  226,   48,  216, 1861,  299, 2552,\n",
       "        102,  210,  561, 2661, 1321, 1020,  165, 2225,   10,    5, 4293,\n",
       "       3166,  710,   58,  165,  111, 4687,   22, 1861, 2227,   10,   12,\n",
       "        299, 2534,  102, 1908,   12,  559,  931,  138,  897,  866, 3164,\n",
       "       9007,   73,  554,   66, 1427,   45, 7313,  216, 6232,  284, 5571,\n",
       "        380,  146,  230,   82, 3241, 1626,  210,  301,  174,   90,    3,\n",
       "        174, 3521, 5669,    5,  710,  382, 1906,  343,   38, 1452,  154,\n",
       "       1257,   36,  125,    4, 8550, 1831,  101, 3088,  333,  858, 1450,\n",
       "         64,  311,   39,    5,   49, 3332, 1626,  226,  177,  419,  138,\n",
       "        205, 1861,    5,  710,   20,   26,   33,  164,   85, 4293,  237,\n",
       "        560,    5,  238,    2,   17, 3431,  191,  240])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokensToString(tokens):\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cartoon comedy ran time school life teaching profession lead believe satire much closer reality scramble survive financially insightful can see right pathetic pomp whole situation remind knew saw episode student repeatedly tried burn school immediately recalled classic line sack one expect many age think far fetched pity isnt'"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cartoon comedy ran time school life teaching profession lead believe satire much closer reality survive financially insightful can see right pathetic whole situation remind knew saw episode student repeatedly tried burn school immediately recalled classic line sack one expect many age think far fetched pity isnt'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokensToString(x_train_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(input_dim=num_words,\n",
    "                    output_dim=embedding_size,\n",
    "                    input_length=max_tokens,\n",
    "                    name='layer_embedding'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### adding LSTM layer & Sigmoid activation along with Adam optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(units=16, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(units=8, return_sequences=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(units=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=1e-3) #optimization algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer_embedding (Embedding)  (None, 206, 8)            80000     \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 206, 16)           1600      \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 206, 8)            800       \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 82,613\n",
      "Trainable params: 82,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numpy = np.array(y_train)\n",
    "y_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "372/372 [==============================] - 49s 131ms/step - loss: 0.4562 - accuracy: 0.7798 - val_loss: 0.4206 - val_accuracy: 0.8296\n",
      "Epoch 2/2\n",
      "372/372 [==============================] - 52s 139ms/step - loss: 0.2682 - accuracy: 0.8977 - val_loss: 0.3219 - val_accuracy: 0.8568\n",
      "Wall time: 1min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23634d1a6a0>"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(x_train_pad, y_numpy,validation_split=0.05, epochs=2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   52,   10, 1465],\n",
       "       [   0,    0,    0, ...,  682,   60,  166],\n",
       "       [   0,    0,    0, ...,  247,  334,  284],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   18,   15,   44],\n",
       "       [   0,    0,    0, ...,  732,    9,   71],\n",
       "       [   0,    0,    0, ...,   37,    6,  802]])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 23s 29ms/step - loss: 0.3300 - accuracy: 0.8587\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model.evaluate(x_test_pad, y_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.33%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy: {0:.2%}\".format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.8680009841919"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ModelAccuracy = result[1] *100\n",
    "ModelAccuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation Analysis for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorrect Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(x=x_test_pad[0:1000])\n",
    "y_pred = y_pred.T[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.55649906, 0.9152925 , 0.80812466, 0.9483121 , 0.9722855 ,\n",
       "       0.75953436, 0.96373737, 0.441306  , 0.91500735, 0.95387596,\n",
       "       0.5761739 , 0.96510154, 0.97451276, 0.9576341 , 0.2115579 ,\n",
       "       0.95213467, 0.9009818 , 0.7374287 , 0.88869965, 0.39838904,\n",
       "       0.5054623 , 0.8378722 , 0.9758344 , 0.89080703, 0.7378894 ,\n",
       "       0.9335265 , 0.85685503, 0.48798683, 0.937719  , 0.9629272 ,\n",
       "       0.9021709 , 0.9712844 , 0.8339702 , 0.96510154, 0.9138565 ,\n",
       "       0.91814196, 0.91899014, 0.9091932 , 0.7605553 , 0.9400674 ,\n",
       "       0.9607535 , 0.9748895 , 0.0557501 , 0.82235813, 0.8758689 ,\n",
       "       0.9607749 , 0.8132056 , 0.9515457 , 0.97193456, 0.96558577,\n",
       "       0.9682784 , 0.58911455, 0.97323453, 0.9589633 , 0.7599933 ,\n",
       "       0.96595454, 0.8862182 , 0.9462483 , 0.83969796, 0.8890484 ,\n",
       "       0.959599  , 0.91382396, 0.95047176, 0.63634217, 0.7620377 ,\n",
       "       0.8133042 , 0.6144052 , 0.9501582 , 0.9536169 , 0.7111784 ,\n",
       "       0.95216495, 0.9572935 , 0.9746804 , 0.04025942, 0.95459473,\n",
       "       0.91308606, 0.9451889 , 0.94002074, 0.7601347 , 0.9618466 ,\n",
       "       0.96754193, 0.03891271, 0.67416483, 0.95924634, 0.83486795,\n",
       "       0.838926  , 0.9214603 , 0.92973185, 0.93970805, 0.91032785,\n",
       "       0.60092235, 0.72341764, 0.9438772 , 0.9760289 , 0.94242144,\n",
       "       0.33715665, 0.41059738, 0.9338246 , 0.97593623, 0.44670272,\n",
       "       0.9601492 , 0.41633767, 0.9330259 , 0.9685023 , 0.9541694 ,\n",
       "       0.9596774 , 0.95111287, 0.96936   , 0.4914444 , 0.6831511 ,\n",
       "       0.9586963 , 0.90082115, 0.9403266 , 0.97255456, 0.9553    ,\n",
       "       0.1066958 , 0.96525055, 0.77690095, 0.27117497, 0.9628668 ,\n",
       "       0.9729749 , 0.9709497 , 0.9499925 , 0.9067821 , 0.97142875,\n",
       "       0.975755  , 0.9746535 , 0.96230423, 0.94664055, 0.47494838,\n",
       "       0.8396939 , 0.96893066, 0.9203453 , 0.9181993 , 0.63310844,\n",
       "       0.96324974, 0.94116807, 0.92036945, 0.9690258 , 0.8996953 ,\n",
       "       0.9511582 , 0.53076786, 0.9750929 , 0.8922201 , 0.50038   ,\n",
       "       0.8146521 , 0.96715033, 0.9543694 , 0.89429384, 0.95488083,\n",
       "       0.946699  , 0.95201325, 0.94145054, 0.8351027 , 0.19714576,\n",
       "       0.8065267 , 0.7833096 , 0.53948826, 0.91778415, 0.75439155,\n",
       "       0.97638786, 0.91038406, 0.9522168 , 0.738923  , 0.84746146,\n",
       "       0.8888744 , 0.11672398, 0.9754902 , 0.30255395, 0.95706433,\n",
       "       0.7065348 , 0.8312611 , 0.3525488 , 0.7233085 , 0.94285405,\n",
       "       0.9737481 , 0.97079444, 0.9181993 , 0.5888206 , 0.84610724,\n",
       "       0.8718673 , 0.97186816, 0.14927056, 0.7871388 , 0.9548153 ,\n",
       "       0.95420873, 0.7332317 , 0.9756048 , 0.19176039, 0.8756579 ,\n",
       "       0.9757894 , 0.62983406, 0.9164171 , 0.68862903, 0.6456932 ,\n",
       "       0.90641713, 0.9534893 , 0.8967092 , 0.30749184, 0.3535617 ,\n",
       "       0.5741322 , 0.93879724, 0.9656313 , 0.969273  , 0.96212673,\n",
       "       0.9274843 , 0.71260196, 0.954185  , 0.5707526 , 0.95340884,\n",
       "       0.92461205, 0.05728933, 0.9220544 , 0.638035  , 0.97616726,\n",
       "       0.04119283, 0.7490694 , 0.89384127, 0.95432925, 0.9262665 ,\n",
       "       0.9545337 , 0.8347163 , 0.58472335, 0.3560484 , 0.93149483,\n",
       "       0.9737698 , 0.9690299 , 0.9654645 , 0.9476261 , 0.9717856 ,\n",
       "       0.87693655, 0.92435145, 0.05391991, 0.6133951 , 0.82750857,\n",
       "       0.18221226, 0.21407309, 0.06179783, 0.8654859 , 0.946141  ,\n",
       "       0.84538823, 0.9444071 , 0.87954986, 0.06192935, 0.51532984,\n",
       "       0.96044254, 0.9503138 , 0.8760274 , 0.9655118 , 0.580403  ,\n",
       "       0.886019  , 0.94011515, 0.87605953, 0.51039004, 0.9666233 ,\n",
       "       0.9565966 , 0.96261513, 0.9733589 , 0.9763069 , 0.74686384,\n",
       "       0.97652745, 0.8144552 , 0.72897124, 0.9548882 , 0.9757111 ,\n",
       "       0.88092655, 0.9495871 , 0.42502713, 0.94857085, 0.91905147,\n",
       "       0.9729248 , 0.8972138 , 0.97035784, 0.9728936 , 0.91307586,\n",
       "       0.90999556, 0.94583446, 0.8787654 , 0.86009675, 0.96399343,\n",
       "       0.45163873, 0.9478476 , 0.96916807, 0.96090984, 0.95888   ,\n",
       "       0.9757039 , 0.9270251 , 0.04197207, 0.9459845 , 0.6515173 ,\n",
       "       0.750718  , 0.9504027 , 0.94978905, 0.96397233, 0.944174  ,\n",
       "       0.95659757, 0.25801784, 0.71614426, 0.95235264, 0.9506874 ,\n",
       "       0.9410203 , 0.9414967 , 0.965717  , 0.93982875, 0.48485833,\n",
       "       0.6858378 , 0.55282176, 0.7891034 , 0.7928281 , 0.9550663 ,\n",
       "       0.9374069 , 0.6655949 , 0.944424  , 0.82691693, 0.7222679 ,\n",
       "       0.29555643, 0.97245705, 0.28966165, 0.40711182, 0.9610431 ,\n",
       "       0.96528363, 0.9146734 , 0.9582876 , 0.96792436, 0.9319278 ,\n",
       "       0.9565827 , 0.9123285 , 0.92614466, 0.95202714, 0.9691379 ,\n",
       "       0.9049537 , 0.9644774 , 0.9185753 , 0.87767196, 0.876197  ,\n",
       "       0.9675391 , 0.12054116, 0.9610026 , 0.92286193, 0.97380453,\n",
       "       0.9422821 , 0.3128817 , 0.6962877 , 0.9630111 , 0.93423724,\n",
       "       0.7819456 , 0.6988327 , 0.87187916, 0.9171256 , 0.8418363 ,\n",
       "       0.97539747, 0.8144735 , 0.95821726, 0.8372391 , 0.6757451 ,\n",
       "       0.9432068 , 0.9286652 , 0.78417313, 0.11984146, 0.14653498,\n",
       "       0.4263178 , 0.95872843, 0.3821994 , 0.9638369 , 0.9708384 ,\n",
       "       0.88123846, 0.96708953, 0.72194433, 0.91690093, 0.9461193 ,\n",
       "       0.91794   , 0.9436881 , 0.8116949 , 0.96555567, 0.9743031 ,\n",
       "       0.75722873, 0.9650605 , 0.9309008 , 0.2964838 , 0.8784544 ,\n",
       "       0.92582595, 0.7427488 , 0.9708631 , 0.8861629 , 0.97020924,\n",
       "       0.60539836, 0.2654863 , 0.96139956, 0.8251064 , 0.9701057 ,\n",
       "       0.97392595, 0.8635199 , 0.07096639, 0.5418122 , 0.3796465 ,\n",
       "       0.12425816, 0.38967118, 0.08382347, 0.7385854 , 0.94165814,\n",
       "       0.9515407 , 0.92702186, 0.7262851 , 0.2620621 , 0.9659388 ,\n",
       "       0.48250756, 0.1027503 , 0.96535504, 0.97040796, 0.96762776,\n",
       "       0.8729167 , 0.9070511 , 0.9142026 , 0.9765021 , 0.96921766,\n",
       "       0.89020115, 0.9645153 , 0.15276095, 0.35656908, 0.5595631 ,\n",
       "       0.96155226, 0.9426559 , 0.9354193 , 0.71815217, 0.8020507 ,\n",
       "       0.9269713 , 0.4636541 , 0.9637573 , 0.82654417, 0.592643  ,\n",
       "       0.9436423 , 0.94016683, 0.9546616 , 0.92287433, 0.05668771,\n",
       "       0.85710466, 0.40364885, 0.35077202, 0.0327763 , 0.19037154,\n",
       "       0.8548261 , 0.94760096, 0.63823867, 0.47887018, 0.9545272 ,\n",
       "       0.8526205 , 0.9059374 , 0.68899804, 0.4709535 , 0.9463811 ,\n",
       "       0.9584601 , 0.9167499 , 0.96260715, 0.96999544, 0.38017637,\n",
       "       0.97549725, 0.84279615, 0.9680048 , 0.94748676, 0.8827802 ,\n",
       "       0.961993  , 0.8629694 , 0.97243166, 0.95140195, 0.974429  ,\n",
       "       0.9699557 , 0.9333801 , 0.9741038 , 0.31640577, 0.90672296,\n",
       "       0.9752116 , 0.57007855, 0.8630626 , 0.62760043, 0.9274397 ,\n",
       "       0.9684583 , 0.58768564, 0.47772178, 0.79295784, 0.86814994,\n",
       "       0.9381603 , 0.9699429 , 0.9758949 , 0.12968731, 0.91884565,\n",
       "       0.9492385 , 0.93949157, 0.95415366, 0.95980465, 0.40124357,\n",
       "       0.9565214 , 0.9505843 , 0.71269655, 0.9758653 , 0.9031924 ,\n",
       "       0.9658756 , 0.21818703, 0.1553917 , 0.9581624 , 0.82113916,\n",
       "       0.9597722 , 0.9110114 , 0.84806097, 0.9709549 , 0.22769615,\n",
       "       0.77150154, 0.518993  , 0.9440206 , 0.9450103 , 0.84046125,\n",
       "       0.9739547 , 0.9591154 , 0.8892245 , 0.92344135, 0.94995606,\n",
       "       0.9177853 , 0.9407687 , 0.7979138 , 0.9308686 , 0.94449615,\n",
       "       0.2522177 , 0.96077645, 0.9424007 , 0.9297338 , 0.95732725,\n",
       "       0.5275299 , 0.9110596 , 0.8538679 , 0.9719951 , 0.97454286,\n",
       "       0.96089214, 0.95598006, 0.86646855, 0.7928009 , 0.9723829 ,\n",
       "       0.917524  , 0.96657866, 0.9545672 , 0.97495437, 0.9180281 ,\n",
       "       0.44750902, 0.967654  , 0.97063714, 0.23935306, 0.9727725 ,\n",
       "       0.79732037, 0.95050955, 0.89399284, 0.73941827, 0.9642222 ,\n",
       "       0.974625  , 0.5801439 , 0.38293275, 0.14537725, 0.78547055,\n",
       "       0.87329006, 0.37288612, 0.5457139 , 0.8707764 , 0.47996697,\n",
       "       0.3526429 , 0.39986402, 0.9034791 , 0.46523702, 0.72112453,\n",
       "       0.9084501 , 0.21632278, 0.47874472, 0.851231  , 0.7494951 ,\n",
       "       0.73186684, 0.24405992, 0.89657724, 0.5921738 , 0.9456661 ,\n",
       "       0.85627466, 0.05452928, 0.9647297 , 0.97020686, 0.85398865,\n",
       "       0.9642167 , 0.81312543, 0.97087276, 0.936589  , 0.7086351 ,\n",
       "       0.68683624, 0.7133728 , 0.9491757 , 0.9667094 , 0.9385878 ,\n",
       "       0.97012997, 0.97295094, 0.19804642, 0.57647324, 0.9636109 ,\n",
       "       0.9755366 , 0.9581988 , 0.7090763 , 0.7831371 , 0.9180794 ,\n",
       "       0.18437463, 0.26567602, 0.17612034, 0.2769307 , 0.8380103 ,\n",
       "       0.39997178, 0.84480345, 0.6352041 , 0.955727  , 0.9336027 ,\n",
       "       0.78091776, 0.10697728, 0.9258145 , 0.04816577, 0.82777107,\n",
       "       0.12949044, 0.8952819 , 0.85470146, 0.92613715, 0.95493656,\n",
       "       0.62977296, 0.9627702 , 0.9464862 , 0.9349437 , 0.8639184 ,\n",
       "       0.07285684, 0.89813554, 0.9687717 , 0.59994245, 0.94007516,\n",
       "       0.97441196, 0.84119165, 0.9602331 , 0.94726956, 0.9481182 ,\n",
       "       0.9286319 , 0.96682894, 0.8816902 , 0.96575093, 0.12460083,\n",
       "       0.9609046 , 0.84309876, 0.9634892 , 0.913082  , 0.9530337 ,\n",
       "       0.04602674, 0.7935951 , 0.97478205, 0.7574589 , 0.5401835 ,\n",
       "       0.4497021 , 0.7612679 , 0.9459659 , 0.4357378 , 0.97126687,\n",
       "       0.56181145, 0.9600375 , 0.83024514, 0.356274  , 0.9176731 ,\n",
       "       0.9640455 , 0.771636  , 0.97414863, 0.96499926, 0.04459387,\n",
       "       0.9753995 , 0.9233831 , 0.5145865 , 0.9267769 , 0.4918953 ,\n",
       "       0.49566612, 0.8344424 , 0.9524268 , 0.9039165 , 0.6759763 ,\n",
       "       0.72317356, 0.87895596, 0.70012164, 0.9683795 , 0.97524357,\n",
       "       0.93884426, 0.91451293, 0.97163445, 0.2836377 , 0.9678205 ,\n",
       "       0.9584886 , 0.85520774, 0.65951025, 0.9726083 , 0.95501864,\n",
       "       0.7454195 , 0.8980957 , 0.9706872 , 0.97462773, 0.9689127 ,\n",
       "       0.89091706, 0.9225672 , 0.9417479 , 0.8366797 , 0.8408704 ,\n",
       "       0.9040283 , 0.919525  , 0.90294355, 0.9708652 , 0.96471673,\n",
       "       0.9564579 , 0.8930888 , 0.9639319 , 0.9170244 , 0.0471831 ,\n",
       "       0.9215071 , 0.8998509 , 0.9606581 , 0.89322925, 0.8915609 ,\n",
       "       0.94398487, 0.71158546, 0.3649543 , 0.9703386 , 0.84440356,\n",
       "       0.958624  , 0.9639564 , 0.92288685, 0.97611266, 0.83524704,\n",
       "       0.8760511 , 0.9655571 , 0.94820404, 0.49214512, 0.9413829 ,\n",
       "       0.9487306 , 0.96798253, 0.96690494, 0.25005203, 0.91395193,\n",
       "       0.951686  , 0.95561147, 0.96689117, 0.17474914, 0.9307344 ,\n",
       "       0.95189357, 0.9592682 , 0.23402995, 0.9455843 , 0.90580976,\n",
       "       0.9200565 , 0.47209293, 0.8612943 , 0.972824  , 0.80860233,\n",
       "       0.9763013 , 0.7423403 , 0.93259573, 0.84213704, 0.9276445 ,\n",
       "       0.94589955, 0.96911216, 0.8728533 , 0.8383224 , 0.5306338 ,\n",
       "       0.8121837 , 0.963467  , 0.960708  , 0.948234  , 0.9405268 ,\n",
       "       0.9760244 , 0.9393424 , 0.45487535, 0.5592239 , 0.80041385,\n",
       "       0.9572648 , 0.3013    , 0.76057416, 0.86276984, 0.79237294,\n",
       "       0.9316945 , 0.96391726, 0.973374  , 0.8457369 , 0.10384804,\n",
       "       0.97334886, 0.79852635, 0.9116064 , 0.96809673, 0.9064214 ,\n",
       "       0.9657031 , 0.7762613 , 0.9317497 , 0.97314984, 0.9741201 ,\n",
       "       0.8419104 , 0.55961925, 0.9732233 , 0.97625184, 0.44147035,\n",
       "       0.972999  , 0.91728175, 0.91450554, 0.22748986, 0.9572238 ,\n",
       "       0.9221891 , 0.97605133, 0.95957243, 0.95469904, 0.96497184,\n",
       "       0.46780697, 0.92410946, 0.9758723 , 0.9597877 , 0.9463828 ,\n",
       "       0.94834167, 0.94487965, 0.8242127 , 0.94446194, 0.9239999 ,\n",
       "       0.1694201 , 0.97381   , 0.97284806, 0.9288601 , 0.05883974,\n",
       "       0.9733885 , 0.9590342 , 0.9721337 , 0.9732154 , 0.9751644 ,\n",
       "       0.83671755, 0.95458794, 0.9392303 , 0.32198822, 0.91274154,\n",
       "       0.6867437 , 0.35977888, 0.95217264, 0.94122374, 0.61441785,\n",
       "       0.9426101 , 0.6804197 , 0.9502909 , 0.8158231 , 0.28271538,\n",
       "       0.9473987 , 0.9757488 , 0.912055  , 0.9043069 , 0.15691146,\n",
       "       0.38932747, 0.96101713, 0.9702854 , 0.8456882 , 0.9759623 ,\n",
       "       0.30578345, 0.9548367 , 0.94406176, 0.9565418 , 0.7000433 ,\n",
       "       0.9210988 , 0.94211435, 0.9664284 , 0.80400467, 0.9245061 ,\n",
       "       0.84504116, 0.8989967 , 0.95340896, 0.97569174, 0.6421184 ,\n",
       "       0.7372793 , 0.78724515, 0.9477113 , 0.8935879 , 0.88169336,\n",
       "       0.91413105, 0.74343276, 0.81771046, 0.8302149 , 0.9726005 ,\n",
       "       0.11800975, 0.7402673 , 0.9698311 , 0.37087375, 0.9769104 ,\n",
       "       0.948522  , 0.976472  , 0.06982073, 0.91632617, 0.941353  ,\n",
       "       0.11148641, 0.9273957 , 0.97421974, 0.58650035, 0.9363488 ,\n",
       "       0.96627116, 0.2751847 , 0.6573566 , 0.96501315, 0.4391419 ,\n",
       "       0.97561085, 0.9670915 , 0.8432517 , 0.658401  , 0.9477114 ,\n",
       "       0.3649596 , 0.9190471 , 0.80577135, 0.74096775, 0.96497524,\n",
       "       0.7096155 , 0.83134246, 0.90095556, 0.95905393, 0.7297795 ,\n",
       "       0.9580959 , 0.96655154, 0.97274274, 0.82601035, 0.6743237 ,\n",
       "       0.09126788, 0.90185976, 0.96218973, 0.9457453 , 0.9580706 ,\n",
       "       0.9706242 , 0.75138915, 0.9758352 , 0.967868  , 0.49633837,\n",
       "       0.9447771 , 0.9720446 , 0.73688626, 0.93424225, 0.9635477 ,\n",
       "       0.6181363 , 0.9709465 , 0.28722614, 0.93033445, 0.91689426,\n",
       "       0.9483777 , 0.96720195, 0.95061004, 0.93775725, 0.91689426,\n",
       "       0.97425926, 0.72383416, 0.9709107 , 0.96735007, 0.9398514 ,\n",
       "       0.8604237 , 0.5918593 , 0.9681423 , 0.7737801 , 0.97531927,\n",
       "       0.90742815, 0.9180335 , 0.9652338 , 0.94489026, 0.527099  ,\n",
       "       0.95901805, 0.9538956 , 0.9132458 , 0.96660423, 0.87849444,\n",
       "       0.9605734 , 0.89128155, 0.9640412 , 0.5430308 , 0.06746   ,\n",
       "       0.43251544, 0.9544598 , 0.96453327, 0.9526888 , 0.5700198 ,\n",
       "       0.13325885, 0.8688605 , 0.3942461 , 0.9259411 , 0.9285314 ,\n",
       "       0.9527918 , 0.9757829 , 0.95793414, 0.9670604 , 0.12292075,\n",
       "       0.927016  , 0.85669535, 0.97204626, 0.9120071 , 0.9455259 ,\n",
       "       0.94015956, 0.9623612 , 0.8497978 , 0.95169663, 0.9691582 ,\n",
       "       0.9012029 , 0.96741563, 0.974979  , 0.9239751 , 0.972416  ,\n",
       "       0.90937054, 0.27710396, 0.94717705, 0.70055985, 0.97053695],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_pred = np.array([1.0 if p>0.5 else 0.0 for p in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_true = np.array(y_test[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect = np.where(cls_pred != cls_true)\n",
    "incorrect = incorrect[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = incorrect[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'felt film many good cinematography certainly different exposing stage aspect set story original certainly achievement felt played quite convincingly course playing definitely unique cultural may leave many disappointed familiarity culture will answer lot regarding parentchild stigma drug use found story interesting note story fashion music reek early even though made really cheesy sometimes crap etc not top ten twenty television check'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = x_test_text[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.441306"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_true[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = np.where(cls_pred == cls_true)\n",
    "correct = correct[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "857"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = correct[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went saw movie last night mine admit reluctant see knew able comedy wrong played character well played professionalism sign good movie can toy one exactly entire theater sold overcome laughter first half movie moved second half exiting theater not saw many many full grown men well trying desperately not let anyone see movie great suggest go see judge'"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = x_test_text[idx]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55649906"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_true[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x=x_test_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,   52,   10, 1465],\n",
       "       [   0,    0,    0, ...,  682,   60,  166],\n",
       "       [   0,    0,    0, ...,  247,  334,  284],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,   18,   15,   44],\n",
       "       [   0,    0,    0, ...,  732,    9,   71],\n",
       "       [   0,    0,    0, ...,   37,    6,  802]])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample testing:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Negative Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this movie is waste of my time, I have no idea why I went to this movie']"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  ['this movie is waste of my time, I have no idea why I went to this movie'] #[\"Hey,this movie is worst than anything I have ever seen\"] #\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 296, 8, 14, 171, 229, 1]]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tokens_temp = tokenizer.texts_to_sequences(x)\n",
    "x_test_tokens_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   1, 296,   8,  14, 171, 229,   1]])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad_temp = pad_sequences(x_test_tokens_temp, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "x_test_pad_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 49 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.16472653], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(x=x_test_pad_temp)\n",
    "y_pred = y_pred.T[0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "if y_pred > 0.5:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positive Case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This movie is the best thing I have ever seen']"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pos = [\"This movie is the best thing I have ever seen\"] #['This movie helped me to improve my whole career'] #\n",
    "x_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 40, 54, 42, 29]]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_tokens_temp_pos = tokenizer.texts_to_sequences(x_pos)\n",
    "x_test_tokens_temp_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 40, 54, 42, 29]])"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_pad_temp_pos = pad_sequences(x_test_tokens_temp_pos, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "x_test_pad_temp_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6562178], dtype=float32)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 60.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.58425206], dtype=float32)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred_pos = model.predict(x=x_test_pad_temp_pos)\n",
    "y_pred_pos = y_pred_pos.T[0]\n",
    "y_pred_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "if y_pred_pos > 0.5:\n",
    "    print(\"Positive\")\n",
    "else:\n",
    "    print(\"Negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=x_train_tokens)\n",
    "classifier = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([('tfidf',tfidf),('clf',classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(x_train_text)\n",
    "X = cv.transform(x_train_text)\n",
    "X_test = cv.transform(x_test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 87.03999999999999\n"
     ]
    }
   ],
   "source": [
    "final_model = LogisticRegression(C=0.05)\n",
    "final_model.fit(X, y_train)\n",
    "LRAccuracyScore = accuracy_score(y_test, final_model.predict(X_test)) * 100\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % LRAccuracyScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 85.184\n"
     ]
    }
   ],
   "source": [
    "model = BernoulliNB()\n",
    "model.fit(X, y_train)\n",
    "BAccuracyScore = accuracy_score(y_test, model.predict(X_test)) * 100\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % BAccuracyScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost Classifier Predicting\n",
      "Final Accuracy: 80.184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "GBC = GradientBoostingClassifier()\n",
    "# Gradient Boost Classifier Fitting\n",
    "GBC.fit(X, y_train)\n",
    "GBCaccuracyScore = accuracy_score(y_test, GBC.predict(X_test)) * 100\n",
    "print (\"Gradient Boost Classifier Predicting\")\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % GBCaccuracyScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagged Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagged Decision Tree Predicting\n",
      "Final Accuracy: 77.068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "BC = BaggingClassifier(base_estimator=DecisionTreeClassifier())\n",
    "# Bagged Decision Tree Fitting\n",
    "BC.fit(X, y_train)\n",
    "\n",
    "BDTaccuracyScore = accuracy_score(y_test, BC.predict(X_test)) * 100\n",
    "print (\"Bagged Decision Tree Predicting\")\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % BDTaccuracyScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 87.164\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "SVM = svm.SVC()\n",
    "SVM.fit(X, y_train)\n",
    "SVMaccuracyScore = accuracy_score(y_test, SVM.predict(X_test)) * 100\n",
    "print (\"Final Accuracy: %s\" \n",
    "       % SVMaccuracyScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our  Neural Network model: 85.87\n",
      "Logistic Regression model: 87.04\n",
      "Bernoulli model: 85.18\n",
      "Gradient Boost Classifier model: 80.18\n",
      "Bagged Decision Tree Classifier model: 77.07\n",
      "Support Vector Machine model: 87.16\n"
     ]
    }
   ],
   "source": [
    "print(\"Our  Neural Network model: %.2f\"%ModelAccuracy)\n",
    "print(\"Logistic Regression model: %.2f\"%LRAccuracyScore)\n",
    "print(\"Bernoulli model: %.2f\"%BAccuracyScore)\n",
    "print(\"Gradient Boost Classifier model: %.2f\"%GBCaccuracyScore)\n",
    "print(\"Bagged Decision Tree Classifier model: %.2f\"%BDTaccuracyScore)\n",
    "print(\"Support Vector Machine model: %.2f\"%SVMaccuracyScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x640 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "objects = ('Our Model', 'LR', 'B', 'GBC', 'BDT', 'SVM')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [ModelAccuracy,LRAccuracyScore,BAccuracyScore,GBCaccuracyScore,BDTaccuracyScore,SVMaccuracyScore]\n",
    "\n",
    "figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "barchart = plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "barchart[0].set_color('r')\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Usage')\n",
    "plt.title('Algorithm Used')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
